#!/usr/bin/env python3
"""
è‡ªå‹•åŒ– UAT æ¸¬è©¦è…³æœ¬
æ¨¡æ“¬ 4 çµ„ä¸åŒä¸»å°é ˜åŸŸçš„ä½¿ç”¨è€…å®Œæˆæ¸¬é©—
"""

import requests
import json
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple

# API åŸºç¤ URL
BASE_URL = "http://localhost:8005"

# é ˜åŸŸèˆ‡ç¶­åº¦æ˜ å°„
DOMAIN_MAPPING = {
    "EXECUTING": ["T1", "T2", "T12"],
    "STRATEGIC_THINKING": ["T3", "T4", "T8"],
    "INFLUENCING": ["T5", "T7", "T11"],
    "RELATIONSHIP_BUILDING": ["T6", "T9", "T10"]
}

DIMENSION_NAMES = {
    "T1": "structured_execution",
    "T2": "quality_perfectionism",
    "T3": "exploration_innovation",
    "T4": "analytical_insight",
    "T5": "influence_advocacy",
    "T6": "collaboration_harmony",
    "T7": "customer_orientation",
    "T8": "learning_growth",
    "T9": "discipline_trust",
    "T10": "pressure_regulation",
    "T11": "conflict_integration",
    "T12": "responsibility_accountability"
}

class UATTester:
    """UAT æ¸¬è©¦åŸ·è¡Œå™¨"""

    def __init__(self, log_dir: str = "logs"):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        self.results = []

    def log(self, message: str):
        """è¨˜éŒ„è¨Šæ¯"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_message = f"[{timestamp}] {message}"
        print(log_message)

    def get_assessment_blocks(self) -> Tuple[str, List[Dict]]:
        """ç²å–è©•æ¸¬é¡Œçµ„"""
        try:
            response = requests.get(f"{BASE_URL}/api/assessment/blocks?v=1")
            response.raise_for_status()
            data = response.json()

            session_id = data.get("session_id")
            blocks = data.get("blocks", [])

            self.log(f"âœ… ç²å–é¡Œçµ„æˆåŠŸ - Session: {session_id}, é¡Œçµ„æ•¸: {len(blocks)}")
            return session_id, blocks

        except Exception as e:
            self.log(f"âŒ ç²å–é¡Œçµ„å¤±æ•—: {e}")
            return None, []

    def identify_target_statement(self, block: Dict, target_talents: List[str]) -> int:
        """è­˜åˆ¥é¡Œçµ„ä¸­å±¬æ–¼ç›®æ¨™é ˜åŸŸçš„èªå¥"""
        statements = block.get("statements", [])
        statement_ids = block.get("statement_ids", [])

        for idx, stmt_id in enumerate(statement_ids):
            # å¾ statement_id æå–ç¶­åº¦ (ä¾‹å¦‚ S_T1_01_Enhanced -> T1)
            parts = stmt_id.split("_")
            if len(parts) >= 2:
                talent = parts[1]  # T1, T2, etc.
                if talent in target_talents:
                    return idx

        # å¦‚æœæ²’æ‰¾åˆ°ç›®æ¨™ç¶­åº¦ï¼Œè¿”å›ç¬¬ä¸€å€‹
        return 0

    def identify_non_target_statement(self, block: Dict, target_talents: List[str]) -> int:
        """è­˜åˆ¥é¡Œçµ„ä¸­ä¸å±¬æ–¼ç›®æ¨™é ˜åŸŸçš„èªå¥"""
        statements = block.get("statements", [])
        statement_ids = block.get("statement_ids", [])

        for idx, stmt_id in enumerate(statement_ids):
            parts = stmt_id.split("_")
            if len(parts) >= 2:
                talent = parts[1]
                if talent not in target_talents:
                    return idx

        # å¦‚æœå…¨æ˜¯ç›®æ¨™ç¶­åº¦ï¼Œè¿”å›æœ€å¾Œä¸€å€‹
        return len(statement_ids) - 1

    def simulate_user_responses(self, blocks: List[Dict], target_domain: str) -> List[Dict]:
        """æ¨¡æ“¬ä½¿ç”¨è€…æ ¹æ“šç›®æ¨™é ˜åŸŸä½œç­”"""
        target_talents = DOMAIN_MAPPING[target_domain]
        responses = []

        self.log(f"ğŸ“ æ¨¡æ“¬ {target_domain} ä¸»å°çš„ä½¿ç”¨è€…ä½œç­”")
        self.log(f"   ç›®æ¨™ç¶­åº¦: {', '.join(target_talents)}")

        start_time = time.time()

        for idx, block in enumerate(blocks):
            block_id = block.get("block_id", idx)

            # é¸æ“‡æœ€ç¬¦åˆï¼šå„ªå…ˆé¸ç›®æ¨™é ˜åŸŸ
            most_like_index = self.identify_target_statement(block, target_talents)

            # é¸æ“‡æœ€ä¸ç¬¦åˆï¼šå„ªå…ˆé¸éç›®æ¨™é ˜åŸŸ
            least_like_index = self.identify_non_target_statement(block, target_talents)

            # ç¢ºä¿ä¸é‡è¤‡
            if most_like_index == least_like_index:
                least_like_index = (most_like_index + 1) % len(block.get("statement_ids", []))

            response_time = int((time.time() - start_time) * 1000)

            response = {
                "question_id": f"q{idx}",
                "most_like_index": most_like_index,
                "least_like_index": least_like_index,
                "block_id": block_id,
                "response_time_ms": response_time
            }

            responses.append(response)

        total_time = int(time.time() - start_time)
        self.log(f"   å®Œæˆ {len(responses)} é¡Œï¼Œç¸½è€—æ™‚: {total_time} ç§’")

        return responses

    def submit_assessment(self, session_id: str, responses: List[Dict]) -> Dict:
        """æäº¤è©•æ¸¬"""
        try:
            total_time = responses[-1]["response_time_ms"] // 1000 if responses else 0

            payload = {
                "session_id": session_id,
                "responses": responses,
                "completion_time_seconds": total_time
            }

            response = requests.post(
                f"{BASE_URL}/api/assessment/submit?v=1",
                json=payload
            )
            response.raise_for_status()

            self.log(f"âœ… æäº¤æˆåŠŸ")
            return response.json()

        except Exception as e:
            self.log(f"âŒ æäº¤å¤±æ•—: {e}")
            return {}

    def get_results(self, session_id: str) -> Dict:
        """ç²å–è©•æ¸¬çµæœ"""
        try:
            response = requests.get(f"{BASE_URL}/api/assessment/results/{session_id}")
            response.raise_for_status()
            data = response.json()

            self.log(f"âœ… ç²å–çµæœæˆåŠŸ")
            return data

        except Exception as e:
            self.log(f"âŒ ç²å–çµæœå¤±æ•—: {e}")
            return {}

    def analyze_results(self, results: Dict, target_domain: str) -> Dict:
        """åˆ†ææ¸¬è©¦çµæœ"""
        target_talents = DOMAIN_MAPPING[target_domain]

        # æå–ç¶­åº¦åˆ†æ•¸ - API è¿”å›æ ¼å¼ç‚º scores è€Œä¸æ˜¯ dimension_scores
        dimension_scores = results.get("scores", results.get("dimension_scores", {}))

        # æŒ‰åˆ†æ•¸æ’åº
        sorted_scores = sorted(dimension_scores.items(), key=lambda x: x[1], reverse=True)

        # æå–ä¸»å°æ‰å¹¹ã€æ”¯æ´æ‰å¹¹ã€å¾…ç®¡ç†é ˜åŸŸ
        dominant = sorted_scores[:4]
        supporting = sorted_scores[4:8]
        lesser = sorted_scores[8:]

        # æª¢æŸ¥ä¸»å°æ‰å¹¹ä¸­åŒ…å«å¤šå°‘ç›®æ¨™ç¶­åº¦
        # è™•ç† API è¿”å›çš„æ ¼å¼ï¼št1_structured_execution æˆ– structured_execution
        dominant_names = [name.split('_', 1)[-1] if '_' in name else name for name, score in dominant]
        target_in_dominant = sum(1 for talent in target_talents if DIMENSION_NAMES[talent] in dominant_names)

        # è¨ˆç®—ç™¾åˆ†ä½å·®è·
        max_percentile = dominant[0][1] if dominant else 0
        min_percentile = lesser[-1][1] if lesser else 0
        gap = max_percentile - min_percentile

        analysis = {
            "target_domain": target_domain,
            "target_talents": target_talents,
            "dominant_talents": dominant,
            "supporting_talents": supporting,
            "lesser_talents": lesser,
            "target_coverage": f"{target_in_dominant}/3",
            "percentile_gap": round(gap, 1),
            "passed": target_in_dominant >= 2
        }

        return analysis

    def format_test_result(self, test_num: int, domain: str, session_id: str, analysis: Dict) -> str:
        """æ ¼å¼åŒ–æ¸¬è©¦çµæœ"""
        lines = []
        lines.append(f"\n{'='*80}")
        lines.append(f"æ¸¬è©¦çµ„ {test_num}ï¼š{domain}")
        lines.append(f"{'='*80}")
        lines.append(f"Session ID: {session_id}")
        lines.append(f"ç›®æ¨™ç¶­åº¦: {', '.join(analysis['target_talents'])}")
        lines.append(f"")

        lines.append(f"ä¸»å°æ‰å¹¹ (Top 4):")
        for idx, (name, score) in enumerate(analysis['dominant_talents'], 1):
            marker = "ğŸ¯" if any(DIMENSION_NAMES[t] == name for t in analysis['target_talents']) else "  "
            lines.append(f"  {idx}. {marker} {name} - {score:.1f}")

        lines.append(f"")
        lines.append(f"æ”¯æ´æ‰å¹¹ (Middle 4):")
        for idx, (name, score) in enumerate(analysis['supporting_talents'], 5):
            lines.append(f"  {idx}. {name} - {score:.1f}")

        lines.append(f"")
        lines.append(f"å¾…ç®¡ç†é ˜åŸŸ (Bottom 4):")
        for idx, (name, score) in enumerate(analysis['lesser_talents'], 9):
            lines.append(f"  {idx}. {name} - {score:.1f}")

        lines.append(f"")
        lines.append(f"é©—è­‰çµæœ:")
        lines.append(f"  ä¸»å°æ‰å¹¹è¦†è“‹ç‡: {analysis['target_coverage']}")
        lines.append(f"  ç™¾åˆ†ä½å·®è·: {analysis['percentile_gap']}")
        lines.append(f"  æ¸¬è©¦é€šé: {'âœ… æ˜¯' if analysis['passed'] else 'âŒ å¦'}")

        return "\n".join(lines)

    def run_test_case(self, test_num: int, domain: str) -> Dict:
        """åŸ·è¡Œå–®å€‹æ¸¬è©¦æ¡ˆä¾‹"""
        self.log(f"\n{'='*80}")
        self.log(f"é–‹å§‹æ¸¬è©¦çµ„ {test_num}: {domain}")
        self.log(f"{'='*80}")

        # 1. ç²å–é¡Œçµ„
        session_id, blocks = self.get_assessment_blocks()
        if not session_id or not blocks:
            return {"error": "ç„¡æ³•ç²å–é¡Œçµ„"}

        # 2. æ¨¡æ“¬ä½œç­”
        responses = self.simulate_user_responses(blocks, domain)

        # 3. æäº¤
        submit_result = self.submit_assessment(session_id, responses)

        # ç­‰å¾…è©•åˆ†å®Œæˆ
        time.sleep(2)

        # 4. ç²å–çµæœ
        results = self.get_results(session_id)

        # 5. åˆ†æçµæœ
        analysis = self.analyze_results(results, domain)
        analysis["session_id"] = session_id

        # 6. æ ¼å¼åŒ–è¼¸å‡º
        result_text = self.format_test_result(test_num, domain, session_id, analysis)
        self.log(result_text)

        # 7. ä¿å­˜åˆ°æ—¥èªŒ
        log_file = self.log_dir / f"test_{test_num}_{domain.lower()}.log"
        with open(log_file, 'w', encoding='utf-8') as f:
            f.write(result_text)

        return analysis

    def run_all_tests(self):
        """åŸ·è¡Œæ‰€æœ‰ 4 çµ„æ¸¬è©¦"""
        test_cases = [
            (1, "EXECUTING"),
            (2, "STRATEGIC_THINKING"),
            (3, "INFLUENCING"),
            (4, "RELATIONSHIP_BUILDING")
        ]

        all_results = []

        for test_num, domain in test_cases:
            result = self.run_test_case(test_num, domain)
            all_results.append(result)
            time.sleep(2)  # é–“éš” 2 ç§’

        # ç”Ÿæˆç¸½çµå ±å‘Š
        self.generate_summary_report(all_results)

        return all_results

    def generate_summary_report(self, results: List[Dict]):
        """ç”Ÿæˆç¸½çµå ±å‘Š"""
        lines = []
        lines.append(f"\n{'='*80}")
        lines.append(f"UAT æ¸¬è©¦ç¸½çµå ±å‘Š")
        lines.append(f"{'='*80}")
        lines.append(f"æ¸¬è©¦æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        lines.append(f"")

        passed_count = sum(1 for r in results if r.get("passed", False))
        total_count = len(results)

        lines.append(f"é€šéç‡: {passed_count}/{total_count} ({passed_count*100//total_count}%)")
        lines.append(f"")

        lines.append(f"{'æ¸¬è©¦çµ„':<5} {'é ˜åŸŸ':<25} {'è¦†è“‹ç‡':<10} {'ç™¾åˆ†ä½å·®':<12} {'é€šé':<6}")
        lines.append(f"{'-'*80}")

        for idx, result in enumerate(results, 1):
            domain = result.get("target_domain", "N/A")
            coverage = result.get("target_coverage", "0/3")
            gap = result.get("percentile_gap", 0)
            passed = "âœ…" if result.get("passed", False) else "âŒ"

            lines.append(f"{idx:<5} {domain:<25} {coverage:<10} {gap:<12.1f} {passed:<6}")

        lines.append(f"")
        lines.append(f"æ¸¬è©¦çµè«–:")
        if passed_count == total_count:
            lines.append(f"  âœ… æ‰€æœ‰æ¸¬è©¦é€šéï¼è©•åˆ†ç³»çµ±æ­£ç¢ºè­˜åˆ¥ä¸åŒä¸»å°é ˜åŸŸã€‚")
        elif passed_count >= total_count * 0.75:
            lines.append(f"  âš ï¸ å¤§éƒ¨åˆ†æ¸¬è©¦é€šéï¼Œä½†æœ‰ {total_count - passed_count} å€‹æ¡ˆä¾‹éœ€è¦æ”¹é€²ã€‚")
        else:
            lines.append(f"  âŒ æ¸¬è©¦å¤±æ•—ï¼Œè©•åˆ†ç³»çµ±éœ€è¦èª¿æ•´ã€‚")

        report_text = "\n".join(lines)
        print(report_text)

        # ä¿å­˜ç¸½çµå ±å‘Š
        summary_file = self.log_dir / "uat_summary_report.log"
        with open(summary_file, 'w', encoding='utf-8') as f:
            f.write(report_text)

        self.log(f"\nğŸ“Š ç¸½çµå ±å‘Šå·²ä¿å­˜åˆ°: {summary_file}")


def main():
    """ä¸»å‡½æ•¸"""
    print("\n" + "="*80)
    print("ğŸš€ é–‹å§‹ UAT è‡ªå‹•åŒ–æ¸¬è©¦")
    print("="*80 + "\n")

    tester = UATTester(log_dir="logs")
    results = tester.run_all_tests()

    print("\n" + "="*80)
    print("âœ… UAT æ¸¬è©¦å®Œæˆï¼")
    print("="*80)
    print(f"\nğŸ“ æ—¥èªŒä½ç½®: logs/")
    print(f"   - test_1_executing.log")
    print(f"   - test_2_strategic_thinking.log")
    print(f"   - test_3_influencing.log")
    print(f"   - test_4_relationship_building.log")
    print(f"   - uat_summary_report.log")


if __name__ == "__main__":
    main()
