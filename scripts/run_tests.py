#!/usr/bin/env python3
"""
æ¸¬è©¦åŸ·è¡Œè…³æœ¬ - Gallup å„ªå‹¢æ¸¬é©—å°ˆæ¡ˆ
æä¾›æ¨™æº–åŒ–çš„æ¸¬è©¦åŸ·è¡Œæ–¹å¼ï¼Œæ”¯æ´ä¸åŒæ¸¬è©¦å ´æ™¯

éµå¾ª comprehensive-testing-plan.md çš„æ¸¬è©¦ç­–ç•¥
ç¬¦åˆ structure_guide.md çš„æ¸¬è©¦æ¶æ§‹
"""

import sys
import subprocess
import argparse
import os
from pathlib import Path
from typing import List, Optional
import time


class TestRunner:
    """æ¸¬è©¦åŸ·è¡Œå™¨"""

    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.output_dir = project_root / "output"
        self.logs_dir = self.output_dir / "logs"
        self.coverage_dir = self.output_dir / "coverage"

        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        self.output_dir.mkdir(exist_ok=True)
        self.logs_dir.mkdir(exist_ok=True)
        self.coverage_dir.mkdir(exist_ok=True)

    def run_unit_tests(self, verbose: bool = True) -> int:
        """åŸ·è¡Œå–®å…ƒæ¸¬è©¦"""
        print("ğŸ§ª åŸ·è¡Œå–®å…ƒæ¸¬è©¦...")

        cmd = [
            "python", "-m", "pytest",
            "src/test/unit/",
            "-m", "unit",
            "--cov=src/main/python",
            "--cov-report=term-missing",
            "--cov-report=html:output/coverage/unit",
            "--junit-xml=output/unit-tests.xml"
        ]

        if verbose:
            cmd.append("-v")

        return self._run_command(cmd, "å–®å…ƒæ¸¬è©¦")

    def run_integration_tests(self, verbose: bool = True) -> int:
        """åŸ·è¡Œæ•´åˆæ¸¬è©¦"""
        print("ğŸ”— åŸ·è¡Œæ•´åˆæ¸¬è©¦...")

        cmd = [
            "python", "-m", "pytest",
            "src/test/integration/",
            "-m", "integration",
            "--junit-xml=output/integration-tests.xml"
        ]

        if verbose:
            cmd.append("-v")

        return self._run_command(cmd, "æ•´åˆæ¸¬è©¦")

    def run_e2e_tests(self, verbose: bool = True) -> int:
        """åŸ·è¡Œç«¯åˆ°ç«¯æ¸¬è©¦"""
        print("ğŸŒ åŸ·è¡Œç«¯åˆ°ç«¯æ¸¬è©¦...")

        cmd = [
            "python", "-m", "pytest",
            "src/test/e2e/",
            "-m", "e2e",
            "--junit-xml=output/e2e-tests.xml",
            "--timeout=60"  # E2E æ¸¬è©¦è¼ƒé•·çš„è¶…æ™‚æ™‚é–“
        ]

        if verbose:
            cmd.append("-v")

        return self._run_command(cmd, "ç«¯åˆ°ç«¯æ¸¬è©¦")

    def run_performance_tests(self, verbose: bool = True) -> int:
        """åŸ·è¡Œæ•ˆèƒ½æ¸¬è©¦"""
        print("âš¡ åŸ·è¡Œæ•ˆèƒ½æ¸¬è©¦...")

        cmd = [
            "python", "-m", "pytest",
            "src/test/",
            "-m", "performance",
            "--benchmark-only",
            "--benchmark-json=output/benchmark.json",
            "--junit-xml=output/performance-tests.xml"
        ]

        if verbose:
            cmd.append("-v")

        return self._run_command(cmd, "æ•ˆèƒ½æ¸¬è©¦")

    def run_smoke_tests(self, verbose: bool = True) -> int:
        """åŸ·è¡Œç…™éœ§æ¸¬è©¦ (å¿«é€Ÿé©—è­‰)"""
        print("ğŸ’¨ åŸ·è¡Œç…™éœ§æ¸¬è©¦...")

        cmd = [
            "python", "-m", "pytest",
            "src/test/",
            "-m", "smoke",
            "--maxfail=1",  # ç¬¬ä¸€å€‹å¤±æ•—å°±åœæ­¢
            "--tb=short",
            "--junit-xml=output/smoke-tests.xml"
        ]

        if verbose:
            cmd.append("-v")

        return self._run_command(cmd, "ç…™éœ§æ¸¬è©¦")

    def run_all_tests(self, verbose: bool = True, fail_fast: bool = False) -> int:
        """åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦"""
        print("ğŸ¯ åŸ·è¡Œå®Œæ•´æ¸¬è©¦å¥—ä»¶...")

        cmd = [
            "python", "-m", "pytest",
            "src/test/",
            "--cov=src/main/python",
            "--cov-report=term-missing",
            "--cov-report=html:output/coverage/all",
            "--cov-report=xml:output/coverage.xml",
            "--junit-xml=output/all-tests.xml"
        ]

        if verbose:
            cmd.append("-v")

        if fail_fast:
            cmd.append("--maxfail=1")

        return self._run_command(cmd, "å®Œæ•´æ¸¬è©¦å¥—ä»¶")

    def run_coverage_report(self) -> int:
        """ç”Ÿæˆè¦†è“‹ç‡å ±å‘Š"""
        print("ğŸ“Š ç”Ÿæˆè¦†è“‹ç‡å ±å‘Š...")

        # å…ˆåŸ·è¡Œæ¸¬è©¦ä»¥ç”Ÿæˆè¦†è“‹ç‡è³‡æ–™
        unit_result = self.run_unit_tests(verbose=False)
        if unit_result != 0:
            print("âŒ å–®å…ƒæ¸¬è©¦å¤±æ•—ï¼Œç„¡æ³•ç”Ÿæˆè¦†è“‹ç‡å ±å‘Š")
            return unit_result

        # ç”Ÿæˆ HTML å ±å‘Š
        cmd = [
            "python", "-m", "coverage", "html",
            "-d", "output/coverage/detailed",
            "--title", "Gallup å„ªå‹¢æ¸¬é©— - ç¨‹å¼ç¢¼è¦†è“‹ç‡å ±å‘Š"
        ]

        result = self._run_command(cmd, "è¦†è“‹ç‡å ±å‘Šç”Ÿæˆ")

        if result == 0:
            print(f"ğŸ“ˆ è¦†è“‹ç‡å ±å‘Šå·²ç”Ÿæˆ: {self.coverage_dir}/detailed/index.html")

        return result

    def run_security_tests(self, verbose: bool = True) -> int:
        """åŸ·è¡Œå®‰å…¨æ¸¬è©¦"""
        print("ğŸ”’ åŸ·è¡Œå®‰å…¨æ¸¬è©¦...")

        cmd = [
            "python", "-m", "pytest",
            "src/test/",
            "-m", "security",
            "--junit-xml=output/security-tests.xml"
        ]

        if verbose:
            cmd.append("-v")

        return self._run_command(cmd, "å®‰å…¨æ¸¬è©¦")

    def run_regression_tests(self, verbose: bool = True) -> int:
        """åŸ·è¡Œå›æ­¸æ¸¬è©¦"""
        print("ğŸ”„ åŸ·è¡Œå›æ­¸æ¸¬è©¦...")

        cmd = [
            "python", "-m", "pytest",
            "src/test/",
            "-m", "regression",
            "--junit-xml=output/regression-tests.xml"
        ]

        if verbose:
            cmd.append("-v")

        return self._run_command(cmd, "å›æ­¸æ¸¬è©¦")

    def _run_command(self, cmd: List[str], test_type: str) -> int:
        """åŸ·è¡Œå‘½ä»¤ä¸¦è™•ç†çµæœ"""
        start_time = time.time()

        try:
            result = subprocess.run(
                cmd,
                cwd=self.project_root,
                capture_output=False,
                text=True,
                env=dict(os.environ, PYTHONPATH=str(self.project_root / "src" / "main" / "python"))
            )

            duration = time.time() - start_time

            if result.returncode == 0:
                print(f"âœ… {test_type} åŸ·è¡ŒæˆåŠŸ ({duration:.2f}s)")
            else:
                print(f"âŒ {test_type} åŸ·è¡Œå¤±æ•— ({duration:.2f}s)")

            return result.returncode

        except FileNotFoundError:
            print("âŒ pytest æœªå®‰è£æˆ–ä¸åœ¨ PATH ä¸­")
            print("è«‹åŸ·è¡Œ: pip install pytest pytest-cov pytest-xdist")
            return 1

        except KeyboardInterrupt:
            print(f"\nâ¹ï¸  {test_type} è¢«ä½¿ç”¨è€…ä¸­æ–·")
            return 130

    def check_dependencies(self) -> bool:
        """æª¢æŸ¥æ¸¬è©¦ä¾è³´æ˜¯å¦å®‰è£"""
        required_packages = [
            "pytest",
            "pytest-cov",
            "pytest-timeout",
            "pytest-benchmark",
            "pytest-mock"
        ]

        missing_packages = []

        for package in required_packages:
            try:
                __import__(package.replace('-', '_'))
            except ImportError:
                missing_packages.append(package)

        if missing_packages:
            print("âŒ ç¼ºå°‘å¿…è¦çš„æ¸¬è©¦å¥—ä»¶:")
            for package in missing_packages:
                print(f"   - {package}")
            print("\nè«‹åŸ·è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£:")
            print(f"pip install {' '.join(missing_packages)}")
            return False

        print("âœ… æ‰€æœ‰æ¸¬è©¦ä¾è³´éƒ½å·²å®‰è£")
        return True

    def cleanup_output(self):
        """æ¸…ç†æ¸¬è©¦è¼¸å‡ºæª”æ¡ˆ"""
        print("ğŸ§¹ æ¸…ç†æ¸¬è©¦è¼¸å‡º...")

        patterns_to_clean = [
            "output/*.xml",
            "output/*.json",
            "output/coverage/*",
            "output/logs/*.log",
            "output/.pytest_cache/*",
            "**/__pycache__",
            "**/*.pyc"
        ]

        for pattern in patterns_to_clean:
            for file_path in self.project_root.glob(pattern):
                if file_path.is_file():
                    file_path.unlink()
                elif file_path.is_dir():
                    import shutil
                    shutil.rmtree(file_path, ignore_errors=True)

        print("âœ… æ¸…ç†å®Œæˆ")


def main():
    """ä¸»å‡½å¼"""
    parser = argparse.ArgumentParser(
        description="Gallup å„ªå‹¢æ¸¬é©—å°ˆæ¡ˆæ¸¬è©¦åŸ·è¡Œå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
æ¸¬è©¦é¡å‹:
  unit        å–®å…ƒæ¸¬è©¦ (70% ç›®æ¨™è¦†è“‹ç‡)
  integration æ•´åˆæ¸¬è©¦ (API + è³‡æ–™åº«)
  e2e         ç«¯åˆ°ç«¯æ¸¬è©¦ (å®Œæ•´ä½¿ç”¨è€…æµç¨‹)
  performance æ•ˆèƒ½æ¸¬è©¦ (åŸºæº–æ¸¬è©¦)
  smoke       ç…™éœ§æ¸¬è©¦ (å¿«é€Ÿé©—è­‰)
  security    å®‰å…¨æ¸¬è©¦
  regression  å›æ­¸æ¸¬è©¦
  all         å®Œæ•´æ¸¬è©¦å¥—ä»¶
  coverage    è¦†è“‹ç‡å ±å‘Š

ç¯„ä¾‹:
  python scripts/run_tests.py unit -v          # è©³ç´°å–®å…ƒæ¸¬è©¦
  python scripts/run_tests.py all --fail-fast  # å¿«é€Ÿå¤±æ•—æ¨¡å¼
  python scripts/run_tests.py smoke -q         # å®‰éœç…™éœ§æ¸¬è©¦
        """
    )

    parser.add_argument(
        "test_type",
        choices=["unit", "integration", "e2e", "performance", "smoke",
                "security", "regression", "all", "coverage", "cleanup"],
        help="è¦åŸ·è¡Œçš„æ¸¬è©¦é¡å‹"
    )

    parser.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="è©³ç´°è¼¸å‡º"
    )

    parser.add_argument(
        "-q", "--quiet",
        action="store_true",
        help="å®‰éœæ¨¡å¼"
    )

    parser.add_argument(
        "--fail-fast",
        action="store_true",
        help="ç¬¬ä¸€å€‹æ¸¬è©¦å¤±æ•—æ™‚åœæ­¢"
    )

    parser.add_argument(
        "--check-deps",
        action="store_true",
        help="åªæª¢æŸ¥ä¾è³´å¥—ä»¶"
    )

    args = parser.parse_args()

    # è¨­å®šå°ˆæ¡ˆæ ¹ç›®éŒ„
    project_root = Path(__file__).parent.parent
    runner = TestRunner(project_root)

    # æª¢æŸ¥ä¾è³´
    if args.check_deps or args.test_type != "cleanup":
        if not runner.check_dependencies():
            return 1

    if args.check_deps:
        return 0

    # è¨­å®šè©³ç´°ç¨‹åº¦
    verbose = args.verbose and not args.quiet

    # åŸ·è¡Œå°æ‡‰çš„æ¸¬è©¦
    test_methods = {
        "unit": runner.run_unit_tests,
        "integration": runner.run_integration_tests,
        "e2e": runner.run_e2e_tests,
        "performance": runner.run_performance_tests,
        "smoke": runner.run_smoke_tests,
        "security": runner.run_security_tests,
        "regression": runner.run_regression_tests,
        "all": runner.run_all_tests,
        "coverage": runner.run_coverage_report,
        "cleanup": runner.cleanup_output
    }

    if args.test_type == "cleanup":
        runner.cleanup_output()
        return 0

    method = test_methods[args.test_type]

    # ç‰¹æ®Šåƒæ•¸è™•ç†
    if args.test_type == "all":
        return method(verbose=verbose, fail_fast=args.fail_fast)
    elif args.test_type == "coverage":
        return method()
    else:
        return method(verbose=verbose)


if __name__ == "__main__":
    sys.exit(main())